{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraper using Selenium\n",
    "\n",
    "Scraper for Twitter Tweets using selenium. It can scrape tweets from:\n",
    "- Home/New Feeds\n",
    "- User Profile Tweets\n",
    "- Query or Search Tweets\n",
    "- Hashtags Tweets\n",
    "- Advanced Search Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from fake_headers import Headers\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException,\n",
    "    WebDriverException,\n",
    ")\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Class\n",
    "\n",
    "Class for the progress of the scraper instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Progress:\n",
    "    def __init__(self, current, total) -> None:\n",
    "        self.current = current\n",
    "        self.total = total\n",
    "        pass\n",
    "\n",
    "    def print_progress(self, current) -> None:\n",
    "        self.current = current\n",
    "        progress = current / self.total\n",
    "        bar_length = 40\n",
    "        progress_bar = (\n",
    "            \"[\"\n",
    "            + \"=\" * int(bar_length * progress)\n",
    "            + \"-\" * (bar_length - int(bar_length * progress))\n",
    "            + \"]\"\n",
    "        )\n",
    "        sys.stdout.write(\n",
    "            \"\\rProgress: [{:<40}] {:.2%} {} of {}\".format(\n",
    "                progress_bar, progress, current, self.total\n",
    "            )\n",
    "        )\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scroller Class\n",
    "\n",
    "Class for the scrollbar of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scroller:\n",
    "    def __init__(self, driver) -> None:\n",
    "        self.driver = driver\n",
    "        self.current_position = 0\n",
    "        self.last_position = driver.execute_script(\"return window.pageYOffset;\")\n",
    "        self.scrolling = True\n",
    "        self.scroll_count = 0\n",
    "        pass\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.current_position = 0\n",
    "        self.last_position = self.driver.execute_script(\"return window.pageYOffset;\")\n",
    "        self.scroll_count = 0\n",
    "        pass\n",
    "\n",
    "    def scroll_to_top(self) -> None:\n",
    "        self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        pass\n",
    "\n",
    "    def scroll_to_bottom(self) -> None:\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        pass\n",
    "\n",
    "    def update_scroll_position(self) -> None:\n",
    "        self.current_position = self.driver.execute_script(\"return window.pageYOffset;\")\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Class\n",
    "\n",
    "Object for the tweet. Including its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        card: WebDriver,\n",
    "        driver: WebDriver,\n",
    "        actions: ActionChains,\n",
    "        scrape_poster_details=False\n",
    "    ) -> None:\n",
    "        self.card = card\n",
    "        self.error = False\n",
    "        self.tweet = None\n",
    "\n",
    "        try:\n",
    "            self.user = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"User-Name\"]//span'\n",
    "            ).text\n",
    "        except NoSuchElementException:\n",
    "            self.error = True\n",
    "            self.user = \"skip\"\n",
    "\n",
    "        try:\n",
    "            self.handle = card.find_element(\n",
    "                \"xpath\", './/span[contains(text(), \"@\")]'\n",
    "            ).text\n",
    "        except NoSuchElementException:\n",
    "            self.error = True\n",
    "            self.handle = \"skip\"\n",
    "\n",
    "        try:\n",
    "            self.date_time = card.find_element(\"xpath\", \".//time\").get_attribute(\n",
    "                \"datetime\"\n",
    "            )\n",
    "\n",
    "            if self.date_time is not None:\n",
    "                self.is_ad = False\n",
    "        except NoSuchElementException:\n",
    "            self.is_ad = True\n",
    "            self.error = True\n",
    "            self.date_time = \"skip\"\n",
    "        \n",
    "        if self.error:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            card.find_element(\n",
    "                \"xpath\", './/*[local-name()=\"svg\" and @data-testid=\"icon-verified\"]'\n",
    "            )\n",
    "\n",
    "            self.verified = True\n",
    "        except NoSuchElementException:\n",
    "            self.verified = False\n",
    "\n",
    "        self.content = \"\"\n",
    "        contents = card.find_elements(\n",
    "            \"xpath\",\n",
    "            '(.//div[@data-testid=\"tweetText\"])[1]/span | (.//div[@data-testid=\"tweetText\"])[1]/a',\n",
    "        )\n",
    "\n",
    "        for index, content in enumerate(contents):\n",
    "            self.content += content.text\n",
    "\n",
    "        try:\n",
    "            self.reply_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"reply\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.reply_cnt == \"\":\n",
    "                self.reply_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.reply_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.retweet_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"retweet\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.retweet_cnt == \"\":\n",
    "                self.retweet_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.retweet_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.like_cnt = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"like\"]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.like_cnt == \"\":\n",
    "                self.like_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.like_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.analytics_cnt = card.find_element(\n",
    "                \"xpath\", './/a[contains(@href, \"/analytics\")]//span'\n",
    "            ).text\n",
    "            \n",
    "            if self.analytics_cnt == \"\":\n",
    "                self.analytics_cnt = \"0\"\n",
    "        except NoSuchElementException:\n",
    "            self.analytics_cnt = \"0\"\n",
    "\n",
    "        try:\n",
    "            self.tags = card.find_elements(\n",
    "                \"xpath\",\n",
    "                './/a[contains(@href, \"src=hashtag_click\")]',\n",
    "            )\n",
    "\n",
    "            self.tags = [tag.text for tag in self.tags]\n",
    "        except NoSuchElementException:\n",
    "            self.tags = []\n",
    "        \n",
    "        try:\n",
    "            self.mentions = card.find_elements(\n",
    "                \"xpath\",\n",
    "                '(.//div[@data-testid=\"tweetText\"])[1]//a[contains(text(), \"@\")]',\n",
    "            )\n",
    "\n",
    "            self.mentions = [mention.text for mention in self.mentions]\n",
    "        except NoSuchElementException:\n",
    "            self.mentions = []\n",
    "        \n",
    "        try:\n",
    "            raw_emojis = card.find_elements(\n",
    "                \"xpath\",\n",
    "                '(.//div[@data-testid=\"tweetText\"])[1]/img[contains(@src, \"emoji\")]',\n",
    "            )\n",
    "            \n",
    "            self.emojis = [emoji.get_attribute(\"alt\").encode(\"unicode-escape\").decode(\"ASCII\") for emoji in raw_emojis]\n",
    "        except NoSuchElementException:\n",
    "            self.emojis = []\n",
    "        \n",
    "        try:\n",
    "            self.profile_img = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"Tweet-User-Avatar\"]//img'\n",
    "            ).get_attribute(\"src\")\n",
    "        except NoSuchElementException:\n",
    "            self.profile_img = \"\"\n",
    "            \n",
    "        try:\n",
    "            self.tweet_link = self.card.find_element(\n",
    "                \"xpath\",\n",
    "                \".//a[contains(@href, '/status/')]\",\n",
    "            ).get_attribute(\"href\")\n",
    "            self.tweet_id = str(self.tweet_link.split(\"/\")[-1])\n",
    "        except NoSuchElementException:\n",
    "            self.tweet_link = \"\"\n",
    "            self.tweet_id = \"\"\n",
    "        \n",
    "        self.following_cnt = \"0\"\n",
    "        self.followers_cnt = \"0\"\n",
    "        self.user_id = None\n",
    "        \n",
    "        if scrape_poster_details:\n",
    "            el_name = card.find_element(\n",
    "                \"xpath\", './/div[@data-testid=\"User-Name\"]//span'\n",
    "            )\n",
    "            \n",
    "            ext_hover_card = False\n",
    "            ext_user_id = False\n",
    "            ext_following = False\n",
    "            ext_followers = False\n",
    "            hover_attempt = 0\n",
    "            \n",
    "            while not ext_hover_card or not ext_user_id or not ext_following or not ext_followers:\n",
    "                try:\n",
    "                    actions.move_to_element(el_name).perform()\n",
    "                    \n",
    "                    hover_card = driver.find_element(\n",
    "                        \"xpath\",\n",
    "                        '//div[@data-testid=\"hoverCardParent\"]'\n",
    "                    )\n",
    "                    \n",
    "                    ext_hover_card = True\n",
    "                    \n",
    "                    while not ext_user_id:\n",
    "                        try:\n",
    "                            raw_user_id = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                '(.//div[contains(@data-testid, \"-follow\")]) | (.//div[contains(@data-testid, \"-unfollow\")])'\n",
    "                            ).get_attribute(\"data-testid\")\n",
    "                            \n",
    "                            if raw_user_id == \"\":\n",
    "                                self.user_id = None\n",
    "                            else:\n",
    "                                self.user_id = str(raw_user_id.split(\"-\")[0])\n",
    "                            \n",
    "                            ext_user_id = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                    \n",
    "                    while not ext_following:\n",
    "                        try:\n",
    "                            self.following_cnt = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                './/a[contains(@href, \"/following\")]//span'\n",
    "                            ).text\n",
    "                            \n",
    "                            if self.following_cnt == \"\":\n",
    "                                self.following_cnt = \"0\"\n",
    "                                \n",
    "                            ext_following = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                    \n",
    "                    while not ext_followers:\n",
    "                        try:\n",
    "                            self.followers_cnt = hover_card.find_element(\n",
    "                                \"xpath\",\n",
    "                                './/a[contains(@href, \"/verified_followers\")]//span'\n",
    "                            ).text\n",
    "                            \n",
    "                            if self.followers_cnt == \"\":\n",
    "                                self.followers_cnt = \"0\"\n",
    "                            \n",
    "                            ext_followers = True\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                        except StaleElementReferenceException:\n",
    "                            self.error = True\n",
    "                            return\n",
    "                except NoSuchElementException:\n",
    "                    if hover_attempt==3:\n",
    "                        self.error\n",
    "                        return\n",
    "                    hover_attempt+=1\n",
    "                    sleep(0.5)\n",
    "                    continue\n",
    "                except StaleElementReferenceException:\n",
    "                    self.error = True\n",
    "                    return\n",
    "            \n",
    "            if ext_hover_card and ext_following and ext_followers:\n",
    "                actions.reset_actions()\n",
    "        \n",
    "        self.tweet = (\n",
    "            self.user,\n",
    "            self.handle,\n",
    "            self.date_time,\n",
    "            self.verified,\n",
    "            self.content,\n",
    "            self.reply_cnt,\n",
    "            self.retweet_cnt,\n",
    "            self.like_cnt,\n",
    "            self.analytics_cnt,\n",
    "            self.tags,\n",
    "            self.mentions,\n",
    "            self.emojis,\n",
    "            self.profile_img,\n",
    "            self.tweet_link,\n",
    "            self.tweet_id,\n",
    "            self.user_id,\n",
    "            self.following_cnt,\n",
    "            self.followers_cnt,\n",
    "        )\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraper Class\n",
    "\n",
    "Class for the Twitter Scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_LOGIN_URL = \"https://twitter.com/i/flow/login\"\n",
    "\n",
    "class Twitter_Scraper:\n",
    "    def __init__(\n",
    "        self,\n",
    "        username,\n",
    "        password,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_poster_details=False,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "    ):\n",
    "        print(\"Initializing Twitter Scraper...\")\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.interrupted = False\n",
    "        self.tweet_ids = set()\n",
    "        self.data = []\n",
    "        self.tweet_cards = []\n",
    "        self.scraper_details = {\n",
    "            \"type\": None,\n",
    "            \"username\": None,\n",
    "            \"hashtag\": None,\n",
    "            \"query\": None,\n",
    "            \"tab\": None,\n",
    "            \"poster_details\": False,\n",
    "        }\n",
    "        self.max_tweets = max_tweets\n",
    "        self.progress = Progress(0, max_tweets)\n",
    "        self.router = self.go_to_home\n",
    "        self.driver = self._get_driver()\n",
    "        self.actions = ActionChains(self.driver)\n",
    "        self.scroller = Scroller(self.driver)\n",
    "        self._config_scraper(\n",
    "            max_tweets,\n",
    "            scrape_username,\n",
    "            scrape_hashtag,\n",
    "            scrape_query,\n",
    "            scrape_latest,\n",
    "            scrape_top,\n",
    "            scrape_poster_details,\n",
    "        )\n",
    "\n",
    "    def _config_scraper(\n",
    "        self,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "        scrape_poster_details=False,\n",
    "    ):\n",
    "        self.tweet_ids = set()\n",
    "        self.data = []\n",
    "        self.tweet_cards = []\n",
    "        self.max_tweets = max_tweets\n",
    "        self.progress = Progress(0, max_tweets)\n",
    "        self.scraper_details = {\n",
    "            \"type\": None,\n",
    "            \"username\": scrape_username,\n",
    "            \"hashtag\": str(scrape_hashtag).replace(\"#\", \"\")\n",
    "            if scrape_hashtag is not None\n",
    "            else None,\n",
    "            \"query\": scrape_query,\n",
    "            \"tab\": \"Latest\" if scrape_latest else \"Top\" if scrape_top else \"Latest\",\n",
    "            \"poster_details\": scrape_poster_details,\n",
    "        }\n",
    "        self.router = self.go_to_home\n",
    "        self.scroller = Scroller(self.driver)\n",
    "\n",
    "        if scrape_username is not None:\n",
    "            self.scraper_details[\"type\"] = \"Username\"\n",
    "            self.router = self.go_to_profile\n",
    "        elif scrape_hashtag is not None:\n",
    "            self.scraper_details[\"type\"] = \"Hashtag\"\n",
    "            self.router = self.go_to_hashtag\n",
    "        elif scrape_query is not None:\n",
    "            self.scraper_details[\"type\"] = \"Query\"\n",
    "            self.router = self.go_to_search\n",
    "        else:\n",
    "            self.scraper_details[\"type\"] = \"Home\"\n",
    "            self.router = self.go_to_home\n",
    "        pass\n",
    "\n",
    "    def _get_driver(self):\n",
    "        print(\"Setup WebDriver...\")\n",
    "        header = Headers().generate()[\"User-Agent\"]\n",
    "\n",
    "        browser_option = ChromeOptions()\n",
    "        browser_option.add_argument(\"--no-sandbox\")\n",
    "        browser_option.add_argument(\"--disable-dev-shm-usage\")\n",
    "        browser_option.add_argument(\"--ignore-certificate-errors\")\n",
    "        browser_option.add_argument(\"--disable-gpu\")\n",
    "        browser_option.add_argument(\"--log-level=3\")\n",
    "        browser_option.add_argument(\"--disable-notifications\")\n",
    "        browser_option.add_argument(\"--disable-popup-blocking\")\n",
    "        browser_option.add_argument(\"--user-agent={}\".format(header))\n",
    "\n",
    "        # For Hiding Browser\n",
    "        browser_option.add_argument(\"--headless\")\n",
    "\n",
    "        try:\n",
    "            print(\"Initializing ChromeDriver...\")\n",
    "            driver = webdriver.Chrome(\n",
    "                options=browser_option,\n",
    "            )\n",
    "\n",
    "            print(\"WebDriver Setup Complete\")\n",
    "            return driver\n",
    "        except WebDriverException:\n",
    "            try:\n",
    "                print(\"Downloading ChromeDriver...\")\n",
    "                chromedriver_path = ChromeDriverManager().install()\n",
    "                chrome_service = ChromeService(executable_path=chromedriver_path)\n",
    "\n",
    "                print(\"Initializing ChromeDriver...\")\n",
    "                driver = webdriver.Chrome(\n",
    "                    service=chrome_service,\n",
    "                    options=browser_option,\n",
    "                )\n",
    "\n",
    "                print(\"WebDriver Setup Complete\")\n",
    "                return driver\n",
    "            except Exception as e:\n",
    "                print(f\"Error setting up WebDriver: {e}\")\n",
    "                sys.exit(1)\n",
    "        pass\n",
    "\n",
    "    def login(self):\n",
    "        print()\n",
    "        print(\"Logging in to Twitter...\")\n",
    "\n",
    "        try:\n",
    "            self.driver.maximize_window()\n",
    "            self.driver.get(TWITTER_LOGIN_URL)\n",
    "            sleep(3)\n",
    "\n",
    "            self._input_username()\n",
    "            self._input_unusual_activity()\n",
    "            self._input_password()\n",
    "\n",
    "            cookies = self.driver.get_cookies()\n",
    "\n",
    "            auth_token = None\n",
    "\n",
    "            for cookie in cookies:\n",
    "                if cookie[\"name\"] == \"auth_token\":\n",
    "                    auth_token = cookie[\"value\"]\n",
    "                    break\n",
    "\n",
    "            if auth_token is None:\n",
    "                raise ValueError(\n",
    "                    \"\"\"This may be due to the following:\n",
    "\n",
    "- Internet connection is unstable\n",
    "- Username is incorrect\n",
    "- Password is incorrect\n",
    "\"\"\"\n",
    "                )\n",
    "\n",
    "            print()\n",
    "            print(\"Login Successful\")\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print()\n",
    "            print(f\"Login Failed: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def _input_username(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                username = self.driver.find_element(\n",
    "                    \"xpath\", \"//input[@autocomplete='username']\"\n",
    "                )\n",
    "\n",
    "                username.send_keys(self.username)\n",
    "                username.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    print()\n",
    "                    print(\n",
    "                        \"\"\"There was an error inputting the username.\n",
    "\n",
    "It may be due to the following:\n",
    "- Internet connection is unstable\n",
    "- Username is incorrect\n",
    "- Twitter is experiencing unusual activity\"\"\"\n",
    "                    )\n",
    "                    self.driver.quit()\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    print(\"Re-attempting to input username...\")\n",
    "                    sleep(2)\n",
    "\n",
    "    def _input_unusual_activity(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                unusual_activity = self.driver.find_element(\n",
    "                    \"xpath\", \"//input[@data-testid='ocfEnterTextTextInput']\"\n",
    "                )\n",
    "                unusual_activity.send_keys(self.username)\n",
    "                unusual_activity.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    break\n",
    "\n",
    "    def _input_password(self):\n",
    "        input_attempt = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                password = self.driver.find_element(\n",
    "                    \"xpath\", \"//input[@autocomplete='current-password']\"\n",
    "                )\n",
    "\n",
    "                password.send_keys(self.password)\n",
    "                password.send_keys(Keys.RETURN)\n",
    "                sleep(3)\n",
    "                break\n",
    "            except NoSuchElementException:\n",
    "                input_attempt += 1\n",
    "                if input_attempt >= 3:\n",
    "                    print()\n",
    "                    print(\n",
    "                        \"\"\"There was an error inputting the password.\n",
    "\n",
    "It may be due to the following:\n",
    "- Internet connection is unstable\n",
    "- Password is incorrect\n",
    "- Twitter is experiencing unusual activity\"\"\"\n",
    "                    )\n",
    "                    self.driver.quit()\n",
    "                    sys.exit(1)\n",
    "                else:\n",
    "                    print(\"Re-attempting to input password...\")\n",
    "                    sleep(2)\n",
    "\n",
    "    def go_to_home(self):\n",
    "        self.driver.get(\"https://twitter.com/home\")\n",
    "        sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_profile(self):\n",
    "        if (\n",
    "            self.scraper_details[\"username\"] is None\n",
    "            or self.scraper_details[\"username\"] == \"\"\n",
    "        ):\n",
    "            print(\"Username is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            self.driver.get(f\"https://twitter.com/{self.scraper_details['username']}\")\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_hashtag(self):\n",
    "        if (\n",
    "            self.scraper_details[\"hashtag\"] is None\n",
    "            or self.scraper_details[\"hashtag\"] == \"\"\n",
    "        ):\n",
    "            print(\"Hashtag is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            url = f\"https://twitter.com/hashtag/{self.scraper_details['hashtag']}?src=hashtag_click\"\n",
    "            if self.scraper_details[\"tab\"] == \"Latest\":\n",
    "                url += \"&f=live\"\n",
    "\n",
    "            self.driver.get(url)\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def go_to_search(self):\n",
    "        if self.scraper_details[\"query\"] is None or self.scraper_details[\"query\"] == \"\":\n",
    "            print(\"Query is not set.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            url = f\"https://twitter.com/search?q={self.scraper_details['query']}&src=typed_query\"\n",
    "            if self.scraper_details[\"tab\"] == \"Latest\":\n",
    "                url += \"&f=live\"\n",
    "\n",
    "            self.driver.get(url)\n",
    "            sleep(3)\n",
    "        pass\n",
    "\n",
    "    def get_tweet_cards(self):\n",
    "        self.tweet_cards = self.driver.find_elements(\n",
    "            \"xpath\", '//article[@data-testid=\"tweet\" and not(@disabled)]'\n",
    "        )\n",
    "        pass\n",
    "\n",
    "    def remove_hidden_cards(self):\n",
    "        try:\n",
    "            hidden_cards = self.driver.find_elements(\n",
    "                \"xpath\", '//article[@data-testid=\"tweet\" and @disabled]'\n",
    "            )\n",
    "\n",
    "            for card in hidden_cards[1:-2]:\n",
    "                self.driver.execute_script(\n",
    "                    \"arguments[0].parentNode.parentNode.parentNode.remove();\", card\n",
    "                )\n",
    "        except Exception as e:\n",
    "            return\n",
    "        pass\n",
    "\n",
    "    def scrape_tweets(\n",
    "        self,\n",
    "        max_tweets=50,\n",
    "        scrape_username=None,\n",
    "        scrape_hashtag=None,\n",
    "        scrape_query=None,\n",
    "        scrape_latest=True,\n",
    "        scrape_top=False,\n",
    "        scrape_poster_details=False,\n",
    "        router=None,\n",
    "    ):\n",
    "        self._config_scraper(\n",
    "            max_tweets,\n",
    "            scrape_username,\n",
    "            scrape_hashtag,\n",
    "            scrape_query,\n",
    "            scrape_latest,\n",
    "            scrape_top,\n",
    "            scrape_poster_details,\n",
    "        )\n",
    "\n",
    "        if router is None:\n",
    "            router = self.router\n",
    "\n",
    "        router()\n",
    "\n",
    "        if self.scraper_details[\"type\"] == \"Username\":\n",
    "            print(\n",
    "                \"Scraping Tweets from @{}...\".format(self.scraper_details[\"username\"])\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Hashtag\":\n",
    "            print(\n",
    "                \"Scraping {} Tweets from #{}...\".format(\n",
    "                    self.scraper_details[\"tab\"], self.scraper_details[\"hashtag\"]\n",
    "                )\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Query\":\n",
    "            print(\n",
    "                \"Scraping {} Tweets from {} search...\".format(\n",
    "                    self.scraper_details[\"tab\"], self.scraper_details[\"query\"]\n",
    "                )\n",
    "            )\n",
    "        elif self.scraper_details[\"type\"] == \"Home\":\n",
    "            print(\"Scraping Tweets from Home...\")\n",
    "\n",
    "        self.progress.print_progress(0)\n",
    "\n",
    "        refresh_count = 0\n",
    "        added_tweets = 0\n",
    "        empty_count = 0\n",
    "\n",
    "        while self.scroller.scrolling:\n",
    "            try:\n",
    "                self.get_tweet_cards()\n",
    "                added_tweets = 0\n",
    "\n",
    "                for card in self.tweet_cards[-15:]:\n",
    "                    try:\n",
    "                        tweet_id = str(card)\n",
    "\n",
    "                        if tweet_id not in self.tweet_ids:\n",
    "                            self.tweet_ids.add(tweet_id)\n",
    "\n",
    "                            if not self.scraper_details[\"poster_details\"]:\n",
    "                                self.driver.execute_script(\n",
    "                                    \"arguments[0].scrollIntoView();\", card\n",
    "                                )\n",
    "\n",
    "                            tweet = Tweet(\n",
    "                                card=card,\n",
    "                                driver=self.driver,\n",
    "                                actions=self.actions,\n",
    "                                scrape_poster_details=self.scraper_details[\n",
    "                                    \"poster_details\"\n",
    "                                ],\n",
    "                            )\n",
    "\n",
    "                            if tweet:\n",
    "                                if not tweet.error and tweet.tweet is not None:\n",
    "                                    if not tweet.is_ad:\n",
    "                                        self.data.append(tweet.tweet)\n",
    "                                        added_tweets += 1\n",
    "                                        self.progress.print_progress(len(self.data))\n",
    "\n",
    "                                        if len(self.data) >= self.max_tweets:\n",
    "                                            self.scroller.scrolling = False\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        continue\n",
    "                                else:\n",
    "                                    continue\n",
    "                            else:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "\n",
    "                if len(self.data) >= self.max_tweets:\n",
    "                    break\n",
    "\n",
    "                if added_tweets == 0:\n",
    "                    if empty_count >= 5:\n",
    "                        if refresh_count >= 3:\n",
    "                            print()\n",
    "                            print(\"No more tweets to scrape\")\n",
    "                            break\n",
    "                        refresh_count += 1\n",
    "                    empty_count += 1\n",
    "                    sleep(1)\n",
    "                else:\n",
    "                    empty_count = 0\n",
    "                    refresh_count = 0\n",
    "            except StaleElementReferenceException:\n",
    "                sleep(2)\n",
    "                continue\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\")\n",
    "                print(\"Keyboard Interrupt\")\n",
    "                self.interrupted = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"\\n\")\n",
    "                print(f\"Error scraping tweets: {e}\")\n",
    "                break\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        if len(self.data) >= self.max_tweets:\n",
    "            print(\"Scraping Complete\")\n",
    "        else:\n",
    "            print(\"Scraping Incomplete\")\n",
    "\n",
    "        print(\"Tweets: {} out of {}\\n\".format(len(self.data), self.max_tweets))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def save_to_csv(self, scraped_username):\n",
    "        print(\"Saving Tweets to CSV...\")\n",
    "        now = datetime.now()\n",
    "        folder_path = \"./tweets/\"\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            print(\"Created Folder: {}\".format(folder_path))\n",
    "\n",
    "        data = {\n",
    "            \"Name\": [tweet[0] for tweet in self.data],\n",
    "            \"Handle\": [tweet[1] for tweet in self.data],\n",
    "            \"Timestamp\": [tweet[2] for tweet in self.data],\n",
    "            \"Verified\": [tweet[3] for tweet in self.data],\n",
    "            \"Content\": [tweet[4] for tweet in self.data],\n",
    "            \"Comments\": [tweet[5] for tweet in self.data],\n",
    "            \"Retweets\": [tweet[6] for tweet in self.data],\n",
    "            \"Likes\": [tweet[7] for tweet in self.data],\n",
    "            \"Analytics\": [tweet[8] for tweet in self.data],\n",
    "            \"Tags\": [tweet[9] for tweet in self.data],\n",
    "            \"Mentions\": [tweet[10] for tweet in self.data],\n",
    "            \"Emojis\": [tweet[11] for tweet in self.data],\n",
    "            \"Profile Image\": [tweet[12] for tweet in self.data],\n",
    "            \"Tweet Link\": [tweet[13] for tweet in self.data],\n",
    "            \"Tweet ID\": [f'tweet_id:{tweet[14]}' for tweet in self.data],\n",
    "        }\n",
    "\n",
    "        if self.scraper_details[\"poster_details\"]:\n",
    "            data[\"Tweeter ID\"] = [f'user_id:{tweet[15]}' for tweet in self.data]\n",
    "            data[\"Following\"] = [tweet[16] for tweet in self.data]\n",
    "            data[\"Followers\"] = [tweet[17] for tweet in self.data]\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        file_path = f\"tweets/{scraped_username}.csv\"\n",
    "        pd.set_option(\"display.max_colwidth\", None)\n",
    "        df.to_csv(file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "        print(\"CSV Saved: {}\".format(file_path))\n",
    "\n",
    "        pass\n",
    "\n",
    "    def get_tweets(self):\n",
    "        return self.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new instance of the Twitter Scraper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Twitter Scraper...\n",
      "Setup WebDriver...\n",
      "Initializing ChromeDriver...\n",
      "WebDriver Setup Complete\n"
     ]
    }
   ],
   "source": [
    "USER_UNAME = os.environ['TWITTER_USERNAME']\n",
    "USER_PASSWORD = os.environ['TWITTER_PASSWORD']\n",
    "\n",
    "scraper = Twitter_Scraper(\n",
    "    username='',\n",
    "    password='',\n",
    "    # max_tweets=10,\n",
    "    # scrape_username=\"something\",\n",
    "    # scrape_hashtag=\"something\",\n",
    "    # scrape_query=\"something\",\n",
    "    # scrape_latest=False,\n",
    "    # scrape_top=True,\n",
    "    # scrape_poster_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging in to Twitter...\n",
      "\n",
      "Login Successful\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scraper.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Twitter Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kurum</th>\n",
       "      <th>Twitter_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TBMM</td>\n",
       "      <td>https://twitter.com/tbmmresmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numan Kurtulmuş</td>\n",
       "      <td>https://twitter.com/NumanKurtulmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TC Cumhurbaşkanlığı</td>\n",
       "      <td>https://twitter.com/tcbestepe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RTE</td>\n",
       "      <td>https://twitter.com/RTErdogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>https://twitter.com/_cevdetyilmaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>İbrahim YUMAKLI</td>\n",
       "      <td>https://twitter.com/ibrahimyumakli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yılmaz Tunç</td>\n",
       "      <td>https://twitter.com/yilmaztunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hakan FİDAN</td>\n",
       "      <td>https://twitter.com/HakanFidan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alparslan BAYRAKTAR</td>\n",
       "      <td>https://twitter.com/aBayraktar1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mehmet ŞİMŞEK</td>\n",
       "      <td>https://twitter.com/memetsimsek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vedat IŞIKHAN</td>\n",
       "      <td>https://twitter.com/isikhanvedat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mehmet ÖZHASEKİ</td>\n",
       "      <td>https://twitter.com/mehmetozhaseki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Abdulkadir URALOĞLU</td>\n",
       "      <td>https://twitter.com/a_uraloglu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mehmet Nuri ERSOY</td>\n",
       "      <td>https://twitter.com/MehmetNuriErsoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahinur ÖZDEMİR GÖKTAŞ</td>\n",
       "      <td>https://twitter.com/MahinurOzdemir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Osman Aşkın BAK</td>\n",
       "      <td>https://twitter.com/OA_BAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ali YERLİKAYA</td>\n",
       "      <td>https://twitter.com/TC_icisleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yusuf TEKİN</td>\n",
       "      <td>https://twitter.com/Yusuf__Tekin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fahrettin KOCA</td>\n",
       "      <td>https://twitter.com/drfahrettinkoca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mehmet Fatih KACIR</td>\n",
       "      <td>https://twitter.com/mfatihkacir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ömer BOLAT</td>\n",
       "      <td>https://twitter.com/omerbolatTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hafize Gaye Erkan</td>\n",
       "      <td>https://twitter.com/hafizegayeerkan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CB Yardımcısı</td>\n",
       "      <td>https://twitter.com/_cevdetyilmaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TC Cumhurbaşkanlığı CB Yardımcısı</td>\n",
       "      <td>https://twitter.com/adalet_bakanlik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TC Tarım ve Orman Bakanlığı</td>\n",
       "      <td>https://twitter.com/TCTarim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TC Adalet Bakanlığı</td>\n",
       "      <td>https://twitter.com/adalet_bakanlik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TC Dış İşleri Bakanlığı</td>\n",
       "      <td>https://twitter.com/TC_Disisleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TC Enerji ve Tabii Kaynak. Bak.</td>\n",
       "      <td>https://twitter.com/TCEnerji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TC Hazine ve Maliye Bakanlığı</td>\n",
       "      <td>https://twitter.com/HMBakanligi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TC Çalışma ve Sosyal Güv. Bak.</td>\n",
       "      <td>https://twitter.com/csgbakanligi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TC Çevre, Şehir, İklim Bak.</td>\n",
       "      <td>https://twitter.com/csbgovtr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TC Ulaştırma ve Altyapı Bak.</td>\n",
       "      <td>https://twitter.com/UABakanligi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TC Kültür ve Turizm Bakanlığı</td>\n",
       "      <td>https://twitter.com/TCKulturTurizm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TC Aile ve Sosyal Hizmetler Bak.</td>\n",
       "      <td>https://twitter.com/tcailesosyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TC Gençlik ve Spor Bak.</td>\n",
       "      <td>https://twitter.com/gencliksporbak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TC İç İşleri Bak.</td>\n",
       "      <td>https://twitter.com/TC_icisleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TC Milli Eğitim Bakanlığı</td>\n",
       "      <td>https://twitter.com/tcmeb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TC Milli Savunma Bakanlığı</td>\n",
       "      <td>https://twitter.com/tcsavunma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TC Sağlık Bakanlığı</td>\n",
       "      <td>https://twitter.com/saglikbakanligi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TC Sanayi ve Teknoloji Bakanlığı</td>\n",
       "      <td>https://twitter.com/TCSanayi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>TC Ticaret Bakanlığı</td>\n",
       "      <td>https://twitter.com/ticaret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TC Merkez Bankası</td>\n",
       "      <td>https://twitter.com/Merkez_Bankasi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Kurum                         Twitter_Link\n",
       "0                                TBMM        https://twitter.com/tbmmresmi\n",
       "1                     Numan Kurtulmuş   https://twitter.com/NumanKurtulmus\n",
       "2                 TC Cumhurbaşkanlığı        https://twitter.com/tcbestepe\n",
       "3                                 RTE        https://twitter.com/RTErdogan\n",
       "4                       Cevdet Yılmaz    https://twitter.com/_cevdetyilmaz\n",
       "5                     İbrahim YUMAKLI   https://twitter.com/ibrahimyumakli\n",
       "6                         Yılmaz Tunç       https://twitter.com/yilmaztunc\n",
       "7                         Hakan FİDAN       https://twitter.com/HakanFidan\n",
       "8                 Alparslan BAYRAKTAR      https://twitter.com/aBayraktar1\n",
       "9                       Mehmet ŞİMŞEK      https://twitter.com/memetsimsek\n",
       "10                      Vedat IŞIKHAN     https://twitter.com/isikhanvedat\n",
       "11                    Mehmet ÖZHASEKİ   https://twitter.com/mehmetozhaseki\n",
       "12                Abdulkadir URALOĞLU       https://twitter.com/a_uraloglu\n",
       "13                  Mehmet Nuri ERSOY  https://twitter.com/MehmetNuriErsoy\n",
       "14             Mahinur ÖZDEMİR GÖKTAŞ   https://twitter.com/MahinurOzdemir\n",
       "15                    Osman Aşkın BAK           https://twitter.com/OA_BAK\n",
       "16                      Ali YERLİKAYA      https://twitter.com/TC_icisleri\n",
       "17                        Yusuf TEKİN     https://twitter.com/Yusuf__Tekin\n",
       "18                     Fahrettin KOCA  https://twitter.com/drfahrettinkoca\n",
       "19                 Mehmet Fatih KACIR      https://twitter.com/mfatihkacir\n",
       "20                         Ömer BOLAT      https://twitter.com/omerbolatTR\n",
       "21                  Hafize Gaye Erkan  https://twitter.com/hafizegayeerkan\n",
       "22                      CB Yardımcısı    https://twitter.com/_cevdetyilmaz\n",
       "23  TC Cumhurbaşkanlığı CB Yardımcısı  https://twitter.com/adalet_bakanlik\n",
       "24        TC Tarım ve Orman Bakanlığı          https://twitter.com/TCTarim\n",
       "25                TC Adalet Bakanlığı  https://twitter.com/adalet_bakanlik\n",
       "26            TC Dış İşleri Bakanlığı     https://twitter.com/TC_Disisleri\n",
       "27    TC Enerji ve Tabii Kaynak. Bak.         https://twitter.com/TCEnerji\n",
       "28      TC Hazine ve Maliye Bakanlığı      https://twitter.com/HMBakanligi\n",
       "29     TC Çalışma ve Sosyal Güv. Bak.     https://twitter.com/csgbakanligi\n",
       "30        TC Çevre, Şehir, İklim Bak.         https://twitter.com/csbgovtr\n",
       "31       TC Ulaştırma ve Altyapı Bak.      https://twitter.com/UABakanligi\n",
       "32      TC Kültür ve Turizm Bakanlığı   https://twitter.com/TCKulturTurizm\n",
       "33   TC Aile ve Sosyal Hizmetler Bak.     https://twitter.com/tcailesosyal\n",
       "34            TC Gençlik ve Spor Bak.   https://twitter.com/gencliksporbak\n",
       "35                  TC İç İşleri Bak.      https://twitter.com/TC_icisleri\n",
       "36          TC Milli Eğitim Bakanlığı            https://twitter.com/tcmeb\n",
       "37         TC Milli Savunma Bakanlığı        https://twitter.com/tcsavunma\n",
       "38                TC Sağlık Bakanlığı  https://twitter.com/saglikbakanligi\n",
       "39   TC Sanayi ve Teknoloji Bakanlığı         https://twitter.com/TCSanayi\n",
       "40               TC Ticaret Bakanlığı          https://twitter.com/ticaret\n",
       "41                  TC Merkez Bankası   https://twitter.com/Merkez_Bankasi"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Kurum': ['TBMM', 'Numan Kurtulmuş', 'TC Cumhurbaşkanlığı', 'RTE', 'Cevdet Yılmaz', 'İbrahim YUMAKLI', 'Yılmaz Tunç', 'Hakan FİDAN', 'Alparslan BAYRAKTAR', 'Mehmet ŞİMŞEK'\n",
    "              , 'Vedat IŞIKHAN', 'Mehmet ÖZHASEKİ', 'Abdulkadir URALOĞLU', 'Mehmet Nuri ERSOY', 'Mahinur ÖZDEMİR GÖKTAŞ', 'Osman Aşkın BAK', \n",
    "              'Ali YERLİKAYA', 'Yusuf TEKİN',  'Fahrettin KOCA', 'Mehmet Fatih KACIR', 'Ömer BOLAT', 'Hafize Gaye Erkan', 'CB Yardımcısı'],\n",
    "    'Twitter_Link': ['https://twitter.com/tbmmresmi', 'https://twitter.com/NumanKurtulmus', 'https://twitter.com/tcbestepe', \n",
    "                     'https://twitter.com/RTErdogan', 'https://twitter.com/_cevdetyilmaz', 'https://twitter.com/ibrahimyumakli',\n",
    "                     'https://twitter.com/yilmaztunc', 'https://twitter.com/HakanFidan', 'https://twitter.com/aBayraktar1', 'https://twitter.com/memetsimsek', \n",
    "                     'https://twitter.com/isikhanvedat', 'https://twitter.com/mehmetozhaseki', 'https://twitter.com/a_uraloglu', 'https://twitter.com/MehmetNuriErsoy',\n",
    "                     'https://twitter.com/MahinurOzdemir', 'https://twitter.com/OA_BAK', 'https://twitter.com/TC_icisleri', 'https://twitter.com/Yusuf__Tekin', \n",
    "                     'https://twitter.com/drfahrettinkoca', 'https://twitter.com/mfatihkacir', 'https://twitter.com/omerbolatTR', 'https://twitter.com/hafizegayeerkan', 'https://twitter.com/_cevdetyilmaz']\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    'Kurum': [\n",
    "        'TBMM',\n",
    "        'TC Cumhurbaşkanlığı',\n",
    "        'TC Cumhurbaşkanlığı CB Yardımcısı',\n",
    "        'TC Tarım ve Orman Bakanlığı',\n",
    "        'TC Adalet Bakanlığı',\n",
    "        'TC Dış İşleri Bakanlığı',\n",
    "        'TC Enerji ve Tabii Kaynak. Bak.',\n",
    "        'TC Hazine ve Maliye Bakanlığı',\n",
    "        'TC Çalışma ve Sosyal Güv. Bak.',\n",
    "        'TC Çevre, Şehir, İklim Bak.',\n",
    "        'TC Ulaştırma ve Altyapı Bak.',\n",
    "        'TC Kültür ve Turizm Bakanlığı',\n",
    "        'TC Aile ve Sosyal Hizmetler Bak.',\n",
    "        'TC Gençlik ve Spor Bak.',\n",
    "        'TC İç İşleri Bak.',\n",
    "        'TC Milli Eğitim Bakanlığı',\n",
    "        'TC Milli Savunma Bakanlığı',\n",
    "        'TC Sağlık Bakanlığı',\n",
    "        'TC Sanayi ve Teknoloji Bakanlığı',\n",
    "        'TC Ticaret Bakanlığı',\n",
    "        'TC Merkez Bankası'\n",
    "    ],\n",
    "    'Twitter_Link': [\n",
    "        'https://twitter.com/tbmmresmi',\n",
    "        'https://twitter.com/tcbestepe',\n",
    "        'https://twitter.com/adalet_bakanlik',\n",
    "        'https://twitter.com/TCTarim',\n",
    "        'https://twitter.com/adalet_bakanlik',\n",
    "        'https://twitter.com/TC_Disisleri',\n",
    "        'https://twitter.com/TCEnerji',\n",
    "        'https://twitter.com/HMBakanligi',\n",
    "        'https://twitter.com/csgbakanligi',\n",
    "        'https://twitter.com/csbgovtr',\n",
    "        'https://twitter.com/UABakanligi',\n",
    "        'https://twitter.com/TCKulturTurizm',\n",
    "        'https://twitter.com/tcailesosyal',\n",
    "        'https://twitter.com/gencliksporbak',\n",
    "        'https://twitter.com/TC_icisleri',\n",
    "        'https://twitter.com/tcmeb',\n",
    "        'https://twitter.com/tcsavunma',\n",
    "        'https://twitter.com/saglikbakanligi',\n",
    "        'https://twitter.com/TCSanayi',\n",
    "        'https://twitter.com/ticaret',\n",
    "        'https://twitter.com/Merkez_Bankasi'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True).drop_duplicates(subset=['Kurum']).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@tbmmresmi',\n",
       " '@NumanKurtulmus',\n",
       " '@tcbestepe',\n",
       " '@RTErdogan',\n",
       " '@_cevdetyilmaz',\n",
       " '@ibrahimyumakli',\n",
       " '@yilmaztunc',\n",
       " '@HakanFidan',\n",
       " '@aBayraktar1',\n",
       " '@memetsimsek',\n",
       " '@isikhanvedat',\n",
       " '@mehmetozhaseki',\n",
       " '@a_uraloglu',\n",
       " '@MehmetNuriErsoy',\n",
       " '@MahinurOzdemir',\n",
       " '@OA_BAK',\n",
       " '@TC_icisleri',\n",
       " '@Yusuf__Tekin',\n",
       " '@drfahrettinkoca',\n",
       " '@mfatihkacir',\n",
       " '@omerbolatTR',\n",
       " '@hafizegayeerkan',\n",
       " '@_cevdetyilmaz',\n",
       " '@adalet_bakanlik',\n",
       " '@TCTarim',\n",
       " '@adalet_bakanlik',\n",
       " '@TC_Disisleri',\n",
       " '@TCEnerji',\n",
       " '@HMBakanligi',\n",
       " '@csgbakanligi',\n",
       " '@csbgovtr',\n",
       " '@UABakanligi',\n",
       " '@TCKulturTurizm',\n",
       " '@tcailesosyal',\n",
       " '@gencliksporbak',\n",
       " '@TC_icisleri',\n",
       " '@tcmeb',\n",
       " '@tcsavunma',\n",
       " '@saglikbakanligi',\n",
       " '@TCSanayi',\n",
       " '@ticaret',\n",
       " '@Merkez_Bankasi']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_handles = [\"@\" + handle for handle in df['Twitter_Link'].str.split('/').str[-1].tolist()]\n",
    "twitter_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Tweets from @@tbmmresmi...\n",
      "Progress: [[============================------------]] 70.00% 7 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 7 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/tbmmresmi.csv\n",
      "Scraping Tweets from @@NumanKurtulmus...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/NumanKurtulmus.csv\n",
      "Scraping Tweets from @@tcbestepe...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/tcbestepe.csv\n",
      "Scraping Tweets from @@RTErdogan...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/RTErdogan.csv\n",
      "Scraping Tweets from @@_cevdetyilmaz...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/_cevdetyilmaz.csv\n",
      "Scraping Tweets from @@ibrahimyumakli...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/ibrahimyumakli.csv\n",
      "Scraping Tweets from @@yilmaztunc...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/yilmaztunc.csv\n",
      "Scraping Tweets from @@HakanFidan...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/HakanFidan.csv\n",
      "Scraping Tweets from @@aBayraktar1...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/aBayraktar1.csv\n",
      "Scraping Tweets from @@memetsimsek...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/memetsimsek.csv\n",
      "Scraping Tweets from @@isikhanvedat...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/isikhanvedat.csv\n",
      "Scraping Tweets from @@mehmetozhaseki...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/mehmetozhaseki.csv\n",
      "Scraping Tweets from @@a_uraloglu...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/a_uraloglu.csv\n",
      "Scraping Tweets from @@MehmetNuriErsoy...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/MehmetNuriErsoy.csv\n",
      "Scraping Tweets from @@MahinurOzdemir...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/MahinurOzdemir.csv\n",
      "Scraping Tweets from @@OA_BAK...\n",
      "Progress: [[================================--------]] 80.00% 8 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 8 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/OA_BAK.csv\n",
      "Scraping Tweets from @@TC_icisleri...\n",
      "Progress: [[================================--------]] 80.00% 8 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 8 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TC_icisleri.csv\n",
      "Scraping Tweets from @@Yusuf__Tekin...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/Yusuf__Tekin.csv\n",
      "Scraping Tweets from @@drfahrettinkoca...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/drfahrettinkoca.csv\n",
      "Scraping Tweets from @@mfatihkacir...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/mfatihkacir.csv\n",
      "Scraping Tweets from @@omerbolatTR...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/omerbolatTR.csv\n",
      "Scraping Tweets from @@hafizegayeerkan...\n",
      "Progress: [[================================--------]] 80.00% 8 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 8 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/hafizegayeerkan.csv\n",
      "Scraping Tweets from @@_cevdetyilmaz...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/_cevdetyilmaz.csv\n",
      "Scraping Tweets from @@adalet_bakanlik...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/adalet_bakanlik.csv\n",
      "Scraping Tweets from @@TCTarim...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TCTarim.csv\n",
      "Scraping Tweets from @@adalet_bakanlik...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/adalet_bakanlik.csv\n",
      "Scraping Tweets from @@TC_Disisleri...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TC_Disisleri.csv\n",
      "Scraping Tweets from @@TCEnerji...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TCEnerji.csv\n",
      "Scraping Tweets from @@HMBakanligi...\n",
      "Progress: [[============================------------]] 70.00% 7 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 7 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/HMBakanligi.csv\n",
      "Scraping Tweets from @@csgbakanligi...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/csgbakanligi.csv\n",
      "Scraping Tweets from @@csbgovtr...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/csbgovtr.csv\n",
      "Scraping Tweets from @@UABakanligi...\n",
      "Progress: [[====================--------------------]] 50.00% 5 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 5 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/UABakanligi.csv\n",
      "Scraping Tweets from @@TCKulturTurizm...\n",
      "Progress: [[============================------------]] 70.00% 7 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 7 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TCKulturTurizm.csv\n",
      "Scraping Tweets from @@tcailesosyal...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/tcailesosyal.csv\n",
      "Scraping Tweets from @@gencliksporbak...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/gencliksporbak.csv\n",
      "Scraping Tweets from @@TC_icisleri...\n",
      "Progress: [[================================--------]] 80.00% 8 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 8 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TC_icisleri.csv\n",
      "Scraping Tweets from @@tcmeb...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/tcmeb.csv\n",
      "Scraping Tweets from @@tcsavunma...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/tcsavunma.csv\n",
      "Scraping Tweets from @@saglikbakanligi...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/saglikbakanligi.csv\n",
      "Scraping Tweets from @@TCSanayi...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/TCSanayi.csv\n",
      "Scraping Tweets from @@ticaret...\n",
      "Progress: [[================================--------]] 80.00% 8 of 10\n",
      "No more tweets to scrape\n",
      "\n",
      "Scraping Incomplete\n",
      "Tweets: 8 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/ticaret.csv\n",
      "Scraping Tweets from @@Merkez_Bankasi...\n",
      "Progress: [[========================================]] 100.00% 10 of 10\n",
      "Scraping Complete\n",
      "Tweets: 10 out of 10\n",
      "\n",
      "Saving Tweets to CSV...\n",
      "CSV Saved: tweets/Merkez_Bankasi.csv\n"
     ]
    }
   ],
   "source": [
    "for user in twitter_handles:\n",
    "    scraper.scrape_tweets(\n",
    "        max_tweets=10,\n",
    "        scrape_username=f\"{user}\",\n",
    "        # scrape_hashtag=\"something\",\n",
    "        # scrape_query=\"something\",\n",
    "        # scrape_latest=False,\n",
    "        # scrape_top=True,\n",
    "        # scrape_poster_details=True,\n",
    "    )\n",
    "    scraper.save_to_csv(user.replace('@', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df handle: ['@aBayraktar1' '@TCEnerji' '@RTErdogan'] | folder name: aBayraktar1\n",
      "df handle: ['@adalet_bakanlik' '@yilmaztunc'] | folder name: adalet_bakanlik\n",
      "df handle: ['@a_uraloglu'] | folder name: a_uraloglu\n",
      "df handle: ['@mehmetozhaseki' '@csbgovtr'] | folder name: csbgovtr\n",
      "df handle: ['@csgbakanligi'] | folder name: csgbakanligi\n",
      "df handle: ['@drfahrettinkoca'] | folder name: drfahrettinkoca\n",
      "df handle: ['@OA_BAK' '@gencliksporbak' '@Olympics'] | folder name: gencliksporbak\n",
      "df handle: ['@hafizegayeerkan'] | folder name: hafizegayeerkan\n",
      "df handle: ['@HakanFidan' '@RTErdogan'] | folder name: HakanFidan\n",
      "df handle: ['@memetsimsek' '@HMBakanligi'] | folder name: HMBakanligi\n",
      "df handle: ['@ibrahimyumakli' '@RTErdogan'] | folder name: ibrahimyumakli\n",
      "df handle: ['@isikhanvedat' '@csgbakanligi' '@RTErdogan'] | folder name: isikhanvedat\n",
      "df handle: ['@MahinurOzdemir' '@RTErdogan'] | folder name: MahinurOzdemir\n",
      "df handle: ['@MehmetNuriErsoy' '@RTErdogan' '@tv100'] | folder name: MehmetNuriErsoy\n",
      "df handle: ['@mehmetozhaseki'] | folder name: mehmetozhaseki\n",
      "df handle: ['@memetsimsek' '@DalrympleWill' '@SkyNews' '@aa_finans' '@AlanRMacLeod'] | folder name: memetsimsek\n",
      "df handle: ['@Merkez_Bankasi'] | folder name: Merkez_Bankasi\n",
      "df handle: ['@mfatihkacir' '@TCSanayi'] | folder name: mfatihkacir\n",
      "df handle: ['@NumanKurtulmus'] | folder name: NumanKurtulmus\n",
      "df handle: ['@mt_goksu' '@RTErdogan' '@OA_BAK' '@murat_kurum'] | folder name: OA_BAK\n",
      "df handle: ['@omerbolatTR' '@RTErdogan' '@ticaret'] | folder name: omerbolatTR\n",
      "df handle: ['@RTErdogan'] | folder name: RTErdogan\n",
      "df handle: ['@drfahrettinkoca' '@saglikbakanligi'] | folder name: saglikbakanligi\n",
      "df handle: ['@NumanKurtulmus' '@TBMMresmi'] | folder name: tbmmresmi\n",
      "df handle: ['@MahinurOzdemir' '@AACanli' '@tcailesosyal' '@anadoluajansi'\n",
      " '@trthabercanli'] | folder name: tcailesosyal\n",
      "df handle: ['@tcbestepe' '@RTErdogan'] | folder name: tcbestepe\n",
      "df handle: ['@aBayraktar1' '@TCEnerji'] | folder name: TCEnerji\n",
      "df handle: ['@TCKulturTurizm' '@MehmetNuriErsoy'] | folder name: TCKulturTurizm\n",
      "df handle: ['@tcmeb' '@Yusuf__Tekin'] | folder name: tcmeb\n",
      "df handle: ['@mfatihkacir' '@TCSanayi' '@Tubitak'] | folder name: TCSanayi\n",
      "df handle: ['@TSKGnkur' '@tcsavunma'] | folder name: tcsavunma\n",
      "df handle: ['@ibrahimyumakli' '@suverimliligiTR' '@milliparklar' '@TCTarim'\n",
      " '@TAGEM_ANKARA' '@canakkaletom'] | folder name: TCTarim\n",
      "df handle: ['@tcbestepe' '@TC_Disisleri' '@RTErdogan'] | folder name: TC_Disisleri\n",
      "df handle: ['@AliYerlikaya' '@TC_icisleri'] | folder name: TC_icisleri\n",
      "df handle: ['@omerbolatTR' '@trthaberekonomi' '@ticaret' '@aa_finans'] | folder name: ticaret\n",
      "df handle: ['@UABakanligi' '@a_uraloglu'] | folder name: UABakanligi\n",
      "df handle: ['@yilmaztunc' '@adalet_bakanlik'] | folder name: yilmaztunc\n",
      "df handle: ['@Yusuf__Tekin' '@RTErdogan'] | folder name: Yusuf__Tekin\n",
      "df handle: ['@_cevdetyilmaz' '@tcbestepe' '@RTErdogan'] | folder name: _cevdetyilmaz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'tweets/'\n",
    "folder_name = os.listdir(folder_path)\n",
    "\n",
    "datasets = []\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        df = pd.read_csv(folder_path + file)\n",
    "        print(f'df handle: {df[\"Handle\"].unique()} | folder name: {file.split(\".\")[0]}')\n",
    "        df = df[df['Handle'] == f'@{file.split(\".\")[0]}']\n",
    "        datasets.append(df)\n",
    "\n",
    "combined_dataset = pd.concat(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Handle\n",
       "@RTErdogan          10\n",
       "@drfahrettinkoca    10\n",
       "@Merkez_Bankasi     10\n",
       "@mehmetozhaseki     10\n",
       "@NumanKurtulmus     10\n",
       "@csgbakanligi       10\n",
       "@a_uraloglu         10\n",
       "@yilmaztunc          9\n",
       "@tcmeb               9\n",
       "@ibrahimyumakli      9\n",
       "@hafizegayeerkan     8\n",
       "@HakanFidan          8\n",
       "@tcbestepe           8\n",
       "@MehmetNuriErsoy     8\n",
       "@Yusuf__Tekin        8\n",
       "@tcsavunma           8\n",
       "@MahinurOzdemir      7\n",
       "@mfatihkacir         7\n",
       "@_cevdetyilmaz       7\n",
       "@isikhanvedat        6\n",
       "@TCSanayi            6\n",
       "@TC_Disisleri        6\n",
       "@TCKulturTurizm      6\n",
       "@aBayraktar1         5\n",
       "@omerbolatTR         5\n",
       "@adalet_bakanlik     5\n",
       "@tcailesosyal        4\n",
       "@memetsimsek         4\n",
       "@TCEnerji            3\n",
       "@UABakanligi         3\n",
       "@gencliksporbak      3\n",
       "@TC_icisleri         2\n",
       "@OA_BAK              2\n",
       "@saglikbakanligi     1\n",
       "@TCTarim             1\n",
       "@HMBakanligi         1\n",
       "@ticaret             1\n",
       "@csbgovtr            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset['Handle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.drop(columns=['Verified', 'Analytics', 'Tags', 'Mentions', 'Emojis', 'Profile Image', 'Tweet Link', 'Tweet ID', 'Comments', 'Retweets', 'Likes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.to_csv('combined_dataset.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T.C. Cumhurbaşkanlığı</td>\n",
       "      <td>@tcbestepe</td>\n",
       "      <td>2024-01-26T15:31:15.000Z</td>\n",
       "      <td>Cumhurbaşkanımız , NATO Genel Sekreteri Jens Stoltenberg ile bir telefon görüşmesi gerçekleştirdi.\\n\\nGörüşmede, küresel ve bölgesel meseleler ve Türkiye'nin İsveç'in NATO üyeliğine verdiği onay ele alındı.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hakan Fidan</td>\n",
       "      <td>@HakanFidan</td>\n",
       "      <td>2024-01-12T19:48:13.000Z</td>\n",
       "      <td>Şehadete eren kahramanlarımıza Allah’tan rahmet; kıymetli ailelerine, yakınlarına ve aziz milletimize başsağlığı ve sabır diliyorum. Şehitlerimizin mekanları cennet, makamları âli olsun. \\n\\nYaralanan askerlerimizin bir an önce sağlıklarına kavuşmasını Cenab-ı Allah’tan niyaz…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-24T17:09:39.000Z</td>\n",
       "      <td>Cumhurbaşkanımız Sayın  ve İran Cumhurbaşkanı Sayın İbrahim Reisi’nin katılımı ile Cumhurbaşkanlığı Külliyesi’nde düzenlenen Türkiye-İran Yüksek Düzeyli İş Birliği Konseyi Sekizinci Toplantısı’na iştirak ettik. \\n\\nToplantı sonrasında Bakanlığımız ile İran Petrol…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name        Handle                 Timestamp  \\\n",
       "0  T.C. Cumhurbaşkanlığı    @tcbestepe  2024-01-26T15:31:15.000Z   \n",
       "1            Hakan Fidan   @HakanFidan  2024-01-12T19:48:13.000Z   \n",
       "4    Alparslan Bayraktar  @aBayraktar1  2024-01-24T17:09:39.000Z   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 Content  \n",
       "0                                                                         Cumhurbaşkanımız , NATO Genel Sekreteri Jens Stoltenberg ile bir telefon görüşmesi gerçekleştirdi.\\n\\nGörüşmede, küresel ve bölgesel meseleler ve Türkiye'nin İsveç'in NATO üyeliğine verdiği onay ele alındı.  \n",
       "1  Şehadete eren kahramanlarımıza Allah’tan rahmet; kıymetli ailelerine, yakınlarına ve aziz milletimize başsağlığı ve sabır diliyorum. Şehitlerimizin mekanları cennet, makamları âli olsun. \\n\\nYaralanan askerlerimizin bir an önce sağlıklarına kavuşmasını Cenab-ı Allah’tan niyaz…  \n",
       "4               Cumhurbaşkanımız Sayın  ve İran Cumhurbaşkanı Sayın İbrahim Reisi’nin katılımı ile Cumhurbaşkanlığı Külliyesi’nde düzenlenen Türkiye-İran Yüksek Düzeyli İş Birliği Konseyi Sekizinci Toplantısı’na iştirak ettik. \\n\\nToplantı sonrasında Bakanlığımız ile İran Petrol…  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-25T12:00:16.000Z</td>\n",
       "      <td>Bugün itibarıyla lisanssız yenilenebilir yatır...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-25T12:00:16.000Z</td>\n",
       "      <td>Bugün itibarıyla lisanssız yenilenebilir yatır...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-24T17:09:39.000Z</td>\n",
       "      <td>Cumhurbaşkanımız Sayın  ve İran Cumhurbaşkanı ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-24T11:43:37.000Z</td>\n",
       "      <td>Cumhurbaşkanımız ve Genel Başkanımız Sayın ‘ın...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alparslan Bayraktar</td>\n",
       "      <td>@aBayraktar1</td>\n",
       "      <td>2024-01-24T09:59:40.000Z</td>\n",
       "      <td>Hollanda Büyükelçisi Sayın Joep Wijnands’ı Bak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>@_cevdetyilmaz</td>\n",
       "      <td>2024-01-26T15:21:17.000Z</td>\n",
       "      <td>Uluslararası Adalet Divanı’nın bugün verdiği k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>@_cevdetyilmaz</td>\n",
       "      <td>2024-01-26T08:26:58.000Z</td>\n",
       "      <td>Anadolu Ajansı muhabirleri ve foto muhabirleri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>@_cevdetyilmaz</td>\n",
       "      <td>2024-01-26T07:26:56.000Z</td>\n",
       "      <td>Kastamonu’da bir yolcu otobüsünün devrilmesi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>@_cevdetyilmaz</td>\n",
       "      <td>2024-01-25T13:22:52.000Z</td>\n",
       "      <td>#Malatya Battalgazi’de meydana gelen depremden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Cevdet Yılmaz</td>\n",
       "      <td>@_cevdetyilmaz</td>\n",
       "      <td>2024-01-24T12:58:13.000Z</td>\n",
       "      <td>Ankara için #HazırızKararlıyızAnkara ilçe bele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name          Handle                 Timestamp  \\\n",
       "0    Alparslan Bayraktar    @aBayraktar1  2024-01-25T12:00:16.000Z   \n",
       "1    Alparslan Bayraktar    @aBayraktar1  2024-01-25T12:00:16.000Z   \n",
       "2    Alparslan Bayraktar    @aBayraktar1  2024-01-24T17:09:39.000Z   \n",
       "3    Alparslan Bayraktar    @aBayraktar1  2024-01-24T11:43:37.000Z   \n",
       "4    Alparslan Bayraktar    @aBayraktar1  2024-01-24T09:59:40.000Z   \n",
       "..                   ...             ...                       ...   \n",
       "226        Cevdet Yılmaz  @_cevdetyilmaz  2024-01-26T15:21:17.000Z   \n",
       "227        Cevdet Yılmaz  @_cevdetyilmaz  2024-01-26T08:26:58.000Z   \n",
       "228        Cevdet Yılmaz  @_cevdetyilmaz  2024-01-26T07:26:56.000Z   \n",
       "229        Cevdet Yılmaz  @_cevdetyilmaz  2024-01-25T13:22:52.000Z   \n",
       "230        Cevdet Yılmaz  @_cevdetyilmaz  2024-01-24T12:58:13.000Z   \n",
       "\n",
       "                                               Content  \n",
       "0    Bugün itibarıyla lisanssız yenilenebilir yatır...  \n",
       "1    Bugün itibarıyla lisanssız yenilenebilir yatır...  \n",
       "2    Cumhurbaşkanımız Sayın  ve İran Cumhurbaşkanı ...  \n",
       "3    Cumhurbaşkanımız ve Genel Başkanımız Sayın ‘ın...  \n",
       "4    Hollanda Büyükelçisi Sayın Joep Wijnands’ı Bak...  \n",
       "..                                                 ...  \n",
       "226  Uluslararası Adalet Divanı’nın bugün verdiği k...  \n",
       "227  Anadolu Ajansı muhabirleri ve foto muhabirleri...  \n",
       "228  Kastamonu’da bir yolcu otobüsünün devrilmesi s...  \n",
       "229  #Malatya Battalgazi’de meydana gelen depremden...  \n",
       "230  Ankara için #HazırızKararlıyızAnkara ilçe bele...  \n",
       "\n",
       "[231 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Handle\n",
       "@RTErdogan          10\n",
       "@drfahrettinkoca    10\n",
       "@Merkez_Bankasi     10\n",
       "@mehmetozhaseki     10\n",
       "@NumanKurtulmus     10\n",
       "@csgbakanligi       10\n",
       "@a_uraloglu         10\n",
       "@yilmaztunc          9\n",
       "@tcmeb               9\n",
       "@ibrahimyumakli      9\n",
       "@hafizegayeerkan     8\n",
       "@HakanFidan          8\n",
       "@tcbestepe           8\n",
       "@MehmetNuriErsoy     8\n",
       "@Yusuf__Tekin        8\n",
       "@tcsavunma           8\n",
       "@MahinurOzdemir      7\n",
       "@mfatihkacir         7\n",
       "@_cevdetyilmaz       7\n",
       "@isikhanvedat        6\n",
       "@TCSanayi            6\n",
       "@TC_Disisleri        6\n",
       "@TCKulturTurizm      6\n",
       "@aBayraktar1         5\n",
       "@omerbolatTR         5\n",
       "@adalet_bakanlik     5\n",
       "@tcailesosyal        4\n",
       "@memetsimsek         4\n",
       "@TCEnerji            3\n",
       "@UABakanligi         3\n",
       "@gencliksporbak      3\n",
       "@TC_icisleri         2\n",
       "@OA_BAK              2\n",
       "@saglikbakanligi     1\n",
       "@TCTarim             1\n",
       "@HMBakanligi         1\n",
       "@ticaret             1\n",
       "@csbgovtr            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset['Handle'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Scraped Tweets in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.save_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
